---
title: "IDS 702 Final Project: Interpreting Hospital Ratings"
author: "Sydney Donati-Leach"
date: "12/12/2021"
output:
  pdf_document: default
  latex_engine: xelatex
geometry: margin=0.5in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# install.packages("cobalt")
# install.packages("MatchIt")
# install.packages("randomForest")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Load libraries
library(cobalt)
library(MatchIt)
library(randomForest)
library(dplyr)
library(xtable)
library(lme4)
library(viridis)
library(sjPlot)
library(qqplotr)
library(arm)
library(pROC)
library(e1071)
library(caret)
library(knitr)
library(MASS)
library(nnet)
library(rms)
library(ordinal)
require(gridExtra)
library(magrittr)
library(stargazer)
library(tidyverse)
```

## Summary:

In order to understand and properly interpret why a hospital receives a certain star rating from the Centers for Medicaid and Medicare Services (CMS), one must take into account different quality measures. Mortality, safety, readmission, and patient experience are the quality measures that have the most impact on the rating. Additionally, the state in which the hospital is located has an impact on the star rating.  The three states with the best hospitals are Ohio, Minnesota and Texas.  The three states with the worst hospitals are Florida, New York, and U.S. territories.

## Introduction:

Every year, CMS rates every hospital registered with Medicare. The rating falls on a scale from one to five: one being the worst, five being the best. This "star rating" is derived from several different quality measures including mortality, safety, readmission, patient experience, timeliness, effectiveness of care, and efficient use of medical imaging. The measures selected come from a wide agreement among CMS, the hospital industry and public sector stakeholders.

All these quality measures are evaluated in comparison to the national average and can be distinguished as above, below or the same as the national average. For example, a hospital could be ranked as below the national average for mortality, but above the national average for patient experience.  Some hospitals may not report enough information on a quality measure for CMS to appropriately assign it a ranking.  In this case, the quality measure will be listed as "Not Available". CMS has stated the weight of the other quality measures will increase in this situation.

The goal of this report will be to interpret which of these quality measures have the strongest impact on the hospital star rating. Additionally, the hospital is put into one of ten different categories regarding its ownership. Therefore, the questions of interest for this report are the following:

  - Which quality measures have the strongest impact on hospital rating?
  -	How does the hospital rating differ for the different types of hospital ownership (e.g., Government, Non-profit, For-profit, etc.)?
  -	Does the hospital rating differ by state? Which states differ the most from other states?

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
### Preprocessing ###

hospital = read.csv("C:/Users/sdona/Documents/Duke/702IDS/FinalProject/Hospital_General_Information.csv", header=TRUE)

hospital$rate <- hospital$Hospital.overall.rating
hospital$ht <- hospital$Hospital.Type 
hospital$owner <- hospital$Hospital.Ownership
hospital$emerg <- hospital$Emergency.Services
hospital$ehr <- hospital$Meets.criteria.for.meaningful.use.of.EHRs
hospital$mortality <- hospital$Mortality.national.comparison
hospital$safety <- hospital$Safety.of.care.national.comparison
hospital$readmis <- hospital$Readmission.national.comparison
hospital$patient_exp <- hospital$Patient.experience.national.comparison
hospital$effective <- hospital$Effectiveness.of.care.national.comparison
hospital$timely <- hospital$Timeliness.of.care.national.comparison
hospital$imaging <- hospital$Efficient.use.of.medical.imaging.national.comparison

# factor all the variables of interest
hospital$ht <- factor(hospital$Hospital.Type)
hospital$owner <- factor(hospital$Hospital.Ownership)
hospital$es <- factor(hospital$Emergency.Services)
hospital$ehr <- factor(hospital$Meets.criteria.for.meaningful.use.of.EHRs)
hospital$mortality <- factor(hospital$Mortality.national.comparison)
hospital$safety <- factor(hospital$Safety.of.care.national.comparison)
hospital$readmis <- factor(hospital$Readmission.national.comparison)
hospital$patient_exp <- factor(hospital$Patient.experience.national.comparison)
hospital$effective <- factor(hospital$Effectiveness.of.care.national.comparison)
hospital$timely <- factor(hospital$Timeliness.of.care.national.comparison)
hospital$imaging <- factor(hospital$Efficient.use.of.medical.imaging.national.comparison)

# remove hospitals that have a rating of "Not Available"
removed_na <- which(hospital$rate != "Not Available")
hospital <- hospital[removed_na,]

# factor the rating with only 5 levels now
hospital$rate <- factor(hospital$Hospital.overall.rating)
```
## Five Level Response:
  
To answer these questions, we will start by excluding state as the hierarchy and build a regular proportional odds model. After we have a model we are satisfied with, we will move to a hierarchical proportional odds model by including the state in which the hospital is located. Our response variable will be the hospital star rating, and the proportional odds model will have five levels (1 to 5).  To look at the number of observations for each star rating, we can see the following distribution:

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
########### response variable ###############
hospital$rate <- ordered(hospital$rate,levels=c("1","2","3","4","5"))

response <- table(hospital$rate)
# sum(response)
print(xtable(response, caption = 'Five Level Response'), caption.placement = 'top', include.colnames = FALSE, comment=FALSE)
```
There are a total of 3567 observations where each observation represents a hospital. This is a relatively normal distribution with the most amount of hospitals falling in the middle at 3, and the least amount of hospitals on the tail ends at 1 and 5.  

### EDA:

Since each of the predictors in this data are factor variables, the only EDA we can do is through tables with the count of observations or the proportions. The first variable to look at is hospital ownership since this is a question of interest. As can be seen in the table below, there are 10 different categories of hospital ownership. The Tribal category only had 2 observations so we cannot take that into account when looking at trends. We can see that the trend does change as Physician owned hospitals have more hospitals with a 5 star rating than any of its other ratings. This is not the case for the other hospital ownership categories, so we will keep this in mind as we move onto model building.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
#############################################
################# EDA #######################
#############################################

######### categorical predictors ############
# ht, owner, emerg, ehr, mortality, safety, readmis, patient_exp, effective, timely, imaging

# hospital type not interesting
# table(hospital$ht, hospital$rate)
# prop.table(table(hospital$rate, hospital$ht), 2)

# hospital ownership IMPORTANT
ownership <- table(hospital$owner, hospital$rate)
print(xtable(ownership, caption = 'Hospital Ownership'), caption.placement = 'top', comment=FALSE)
# prop.table(table(hospital$rate, hospital$owner), 2)
```

There were two quality measures that were the most interesting and the tables of proportions can be seen below. First, if a hospital was ranked below the national average for mortality, 0% of those hospitals received a 5 star rating. Second, if a hospital was ranked below the national average for patient experience $or$ it was not available, 0% of those hospitals received a 5 star rating.  Readmission follows close behind where 0.12% of hospitals received a 5 star rating if this quality measure was rated below the national average. The remaining quality measures are safety, timeliness, effectiveness of care, and efficient imaging. If any of these quality measures were ranked below the national average, between 0.3% to 1.9% of hospitals were able to receive a 5 star rating. Based purely on this EDA, it appears the quality measures in this order have a decreasing significance on the star rating, but we will need to explore this further in model building.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# mortality IMPORTANT
mortality <- prop.table(table(hospital$rate, hospital$mortality), 1)
print(xtable(mortality, caption = 'Mortality'), caption.placement = 'top', comment=FALSE)

# safety semi important
# table(hospital$safety, hospital$rate)
# prop.table(table(hospital$rate, hospital$safety), 2)

# readmission
# table(hospital$readmis, hospital$rate)
# prop.table(table(hospital$rate, hospital$readmis), 2)

# patient experience IMPORTANT
patient <- prop.table(table(hospital$rate, hospital$patient_exp), 1)
print(xtable(patient, caption = 'Patient Experience'), caption.placement = 'top', comment=FALSE)


# effectiveness of care
# table(hospital$effective, hospital$rate)
# prop.table(table(hospital$rate, hospital$effective), 2)

# timeliness of care
# table(hospital$timely, hospital$rate)
# prop.table(table(hospital$rate, hospital$timely), 2)

# Efficient use of medical imaging
# table(hospital$imaging, hospital$rate)
# prop.table(table(hospital$rate, hospital$imaging), 2)
```

One more point on EDA is that we will not be able to look at any interactions of variables due to the lack of observations when these quality measures are broken up.

### Model Building:

After taking into consideration everything we learned from EDA, we will start to build our proportional odds model. The first model will be simple and only contain the 2 quality measures we found the most interesting: mortality and patient experience.  Moving to the second model, we will add readmission to the model. To test the significance of readmission, we can do an ANOVA Chi-squared test. Readmission is statistically significant, so we can move onto the next model with that included and test the next quality measure, safety, for significance.  After repeating this process for all of the quality measures, we will find that all are statistically significant, so we will want to include all of them in our model. After solidifying all the necessary quality measures in the model, the last step is adding hospital ownership, and this is statistically significant as well.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# test the quality measures one at a time
model_1 <- polr(rate ~ mortality + patient_exp, data=hospital)

model_2 <- polr(rate ~ mortality + patient_exp + readmis, data=hospital)

# anova(model_1, model_2, test = "Chisq")

model_3 <- polr(rate ~ mortality + patient_exp + readmis + safety, data=hospital)

# anova(model_2, model_3, test = "Chisq")

model_4 <- polr(rate ~ mortality + patient_exp + readmis + safety + effective, data=hospital)

# anova(model_3, model_4, test = "Chisq")

model_5 <- polr(rate ~ mortality + patient_exp + readmis + safety + effective + timely, data=hospital)

# anova(model_4, model_5, test = "Chisq")

model_6 <- polr(rate ~ mortality + patient_exp + readmis + safety + effective + timely + imaging, data=hospital)

# anova(model_5, model_6, test = "Chisq")

# model 7: add owner
model_7 <- polr(rate ~ owner + mortality + safety + readmis + patient_exp + effective + timely + imaging, data=hospital)

# anova(model_6, model_7, test = "Chisq")


# move forward with model 3 in the hierarchical model
# don't need to check for multicolinearity because they are all factor variables

```

Based on what we learned from the ANOVA Chi-squared tests, our proportional odds model is as follows:

$$
log \left ( \frac{Pr[y_{i}\leq j|x^{_{i}}]}
{Pr[y_{i}>j|x^{_{i}}]}  \right ) 
 = \beta _{0j} + \beta_{1}x_{i1} + \beta_{2}x_{i2} + \beta_{3}x_{i3} + \beta_{4}x_{i4} + \beta_{5}x_{i5} + 
$$
$$
 \beta_{6}x_{i6} + \beta_{7}x_{i7} + \beta_{8}x_{i8},\ \ j=1,...,J-1
$$

On the left side of the equation, we combine the first $j$ star rating to form a single category and the remaining $j$ star ratings to form a second category, where $i$ represents hospitals.  On the right side of the equation we have our predictors where $x_{i1}$ is $owner$, $x_{i2}$ is $mortality$,  $x_{i3}$ is $safety$,  $x_{i4}$ is $readmis$,  $x_{i5}$ is $patient\_exp$,  $x_{i6}$ is $effective$, $x_{i7}$ is $timely$, and $x_{i8}$ is $imaging$.

We will not do any interpretation of this model as this is not our final model. We still need to explore hierarchy based on state, and this will be covered in the next section.

## Three Level Response:

As stated before, the next step will be to include state as the hierarchy and build a hierarchical proportional odds model.  However, we do not have enough observations to do this with a five level response.  Therefore, we will reduce our response to only 3 levels.  In this case, an original star rating of 1 or 2 would be mapped to a rating of 1, an original star rating of 3 would be mapped to 2, and an original star rating of 4 or 5 would be mapped to a 3.  By collapsing the response to only 3 levels, there will be more observations present in each category for each state.  An additional step we will take is collapse the U.S. territories of American Samoa, Guam, Puerto Rico, Virgin Islands, and Northern Mariana Islands into a state called "Others".  These territories do not have many observations on their own, so combining them will allow us to evaluate their hospitals without being removed from the model.

After doing this, we can see the following distribution of observations:
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
################################################################################
########################## Prop Odds 3 Levels ##################################
################################################################################

# couldn't include state before because the levels have too few data
# can collapse the ratings to 1,2,3 and US territories to others

# combine U.S. territories that have few obs
territories <- c("AS","GU","MP","PR","VI")
hospital$State[is.element(hospital$State,territories)] <- "Others"

# factor the states now
hospital$State <- factor(hospital$State)

hospital$rate_new <- "1"
hospital$rate_new[hospital$rate == 2]<- "1"
hospital$rate_new[hospital$rate == 3]<- "2"
hospital$rate_new[hospital$rate == 4]<- "3"
hospital$rate_new[hospital$rate == 5]<- "3"

# factor the rating with only 3 levels now
hospital$rate_new <- factor(hospital$rate_new)

# order the new ratings
hospital$rate_new <- ordered(hospital$rate_new,levels=c("1","2","3"))

#############################################
################# EDA #######################
#############################################

########### response variable ###############
new_response <- table(hospital$rate_new)
# sum(new_response)
print(xtable(new_response, caption = 'Three Level Response'), caption.placement = 'top', include.colnames = FALSE, comment=FALSE)

```
### EDA:
When introducing a hierarchy, we must determine if there is varying intercept and/or varying slope. We can do this by looking at the count and proportions of observations for all the states.  Based on the count of observations, it is clear that we will not be able to account for varying slope as there are less than 10 observations for many states. In addition, 7 states are missing observations when split across the 3 star ratings. However, when we look at the proportions of observations, the trend is not the same across states. For example, 89% of hospitals in Alaska have a 2 star rating. This differs greatly from D.C. in which only 14% of hospitals have a 2 star rating.  Therefore, we will need to add varying intercept to our model.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
########### varying intercept ###############

# table(hospital$State, hospital$rate_new)
states <- prop.table(table(hospital$State, hospital$rate_new), 1)
# print(xtable(states), comment=FALSE)
```

### Modeling Building:

We will use our model from the five level response as our base model to build on.  We can begin by adding state simply as a categorical variable, but this does not allow information to be shared across states.  Therefore, we will fit a hierarchical model to explore the random effects that different states may contribute to the model. States are used as the only hierarchy in the model. Again, random slopes were not considered as the model would not have been able to converge which such few observations within many of the states.

Our final hierarchical proportional odds model is as follows:
$$
log \left ( \frac{Pr[y_{i}\leq j|x^{_{i}}]}
{Pr[y_{i}>j|x^{_{i}}]}  \right ) 
 = \beta _{0j} + \gamma_i + X_i\beta, \ \  j=1,...,J-1
$$
All of the same variables from the previous proportional odds model are represented by the vector $X$ in this simplified equation. The only addition is that we now have a random intercept of $state$ represented by $\gamma$.

The model summary shown below will be the basis for all interpretations and answers to our questions of interest.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
##################################################
################# Modeling #######################
##################################################

# use model 4 as the only model to build hierarchy on

# attempt to model with State as a categorical variable
# hier_model1 <- clm(rate_new ~ State + mortality + safety + readmis + patient_exp + effective + timely + imaging, data=hospital)
# tab_model(hier_model1)

## change the reference level of hospital ownership
hospital$owner <- relevel(as.factor(hospital$owner), ref = "Government - Federal")

hier_model2 <- clmm(rate_new ~ owner + mortality + safety + readmis + patient_exp + effective + timely + imaging + (1|State), data=hospital)

# print(xtable(summary(hier_model2)), comment=FALSE)
tab_model(hier_model2)
# stargazer(hier_model2)
```

First, it is important to note that for our response of 1|2 and 2|3 the coefficients are not actually zero, but are extremely small. Secondly, our baseline in the model is a Government Federally owned hospital, with all of the quality measures ranked above the national average. The Voluntary non-profit hospitals all have coefficients larger than 1, signifying that the odds of these hospitals receiving a rating towards a 5 rather than towards a 1 is roughly two times greater than a Federally owned hospital. However, this is not statistically significant due to the p-values being greater than 0.05. 

Moving onto our quality measures, all of these coefficients are less than one which is reasonable given that our baseline hospital had all its quality measures above the national average. Additionally, almost all of the variables are significant. For 4 variables (mortality, safety, readmission, and patient experience) we see the exact same coefficient of 0.01 when the quality measure is ranked below the national average.  This means that if a hospital receives a ranking below the national average in one of these quality measures, it is 99% less likely to get a star rating towards a 5.

For the other 3 quality measures, (timeliness, effectiveness of care, and efficient imaging), the coefficients are larger when it is ranked below the national average.  For example, if a hospital receives a ranking below the national average for timely care, it is only 64% less likely to get a star rating towards a 5. This shows that these 3 quality measures have less of an impact on the overall star rating, as compared to the other 4 quality measures.

If we look at the random effects of this model, the standard deviation of star ratings between states is 0.23. We can also evaluate which states have hospitals with star ratings necessarily worse or better than the other states' hospitals.  The three states with the best hospitals are Ohio, Minnesota and Texas.  The three states with the worst hospitals are Florida, New York, and the U.S. territories we combined into "Others." Figure 1 in the appendix shows a full map of the United States designating which states are in the top half in the country verses the bottom half.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# see which states are better/worse off
effects <- ranef(hier_model2,condVar = T)$State
# sort from largest to smallest
# sort(effects$`(Intercept)`)

# best
  # TX      0.276015939
  # OH      0.261337967
  # MN      0.249608508

# worst
  # Others -0.269373101
  # FL     -0.257923148
  # NY     -0.233823510
```

Finally, regarding model assessment, we are not able to create binned plots of residuals since all of our variables are factor variables.  Additionally, we cannot look at a binned residual plot of the overall expected values.  The cumulative link mixed model (clmm) that was used for this hierarchical proportional odds model creates cumulative predicted probabilities from the fitted values rather than exact predicted probabilities. 

## Conclusions:

We were able to answer all of our questions of interest using the hierarchical proportional odds model.  The answers are as follows:

  - Which quality measures have the strongest impact on hospital rating?
      - Mortality, safety, readmission, and patient experience.
  -	How does the hospital rating differ for the different types of hospital ownership (e.g., Government, Non-profit, For-profit, etc.)?
      - The ratings do differ by hospital ownership, and voluntary non-profit hospitals may potentially outperform the other hospitals, but the lack of statistical significance makes this an inconclusive statement.
  -	Does the hospital rating differ by state? Which states differ the most from other states?
      - Yes.  The three states with the best hospitals are Ohio, Minnesota and Texas.  The three states with the worst hospitals are Florida, New York, and the U.S. territories we combined into "Others".

The limitations to this report came down to the data available, and the limited number of observations in certain categories.  If there were more observations, we would have been able to explore interactions, and we would not have had to switch from a 5 level response to a 3 level response.  Along those same lines, we might have been able to explore random slopes and determine if there is any variation within states. The future potential of this project would be to add in more years of data to gain more observations.

